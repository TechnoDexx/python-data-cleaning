{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/BL-Flickr-Images-Book.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Edition Statement',\n",
    "           'Corporate Author',\n",
    "           'Corporate Contributors',\n",
    "           'Former owner',\n",
    "           'Engraver',\n",
    "           'Contributors',\n",
    "           'Issuance type',\n",
    "           'Shelfmarks']\n",
    "\n",
    "df.drop(to_drop, inplace = True, axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the index of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Identifier', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date of Publication'].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns using the `.apply` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_characters = ['[', ',', '-']\n",
    "\n",
    "def clean_dates(item):\n",
    "    dop= str(item.loc['Date of Publication'])\n",
    "    \n",
    "    if dop == 'nan' or dop[0] == '[':\n",
    "        return np.NaN\n",
    "    \n",
    "    for character in unwanted_characters:\n",
    "        if character in dop:\n",
    "            character_index = dop.find(character)\n",
    "            dop = dop[:character_index]\n",
    "    \n",
    "    return dop\n",
    "\n",
    "df['Date of Publication'] = df.apply(clean_dates, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate way of cleaning Date of Publication\n",
    "#run cell to see output\n",
    "unwanted_characters = ['[', ',', '-']\n",
    "\n",
    "def clean_dates(dop):\n",
    "    dop = str(dop)\n",
    "    if dop.startswith('[') or dop == 'nan':\n",
    "        return 'NaN'\n",
    "    for character in unwanted_characters:\n",
    "        if character in dop:\n",
    "            character_index = dop.find(character)\n",
    "            dop = dop[:character_index]\n",
    "    return dop\n",
    "\n",
    "df['Date of Publication'] = df['Date of Publication'].apply(clean_dates)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_author_names(author):\n",
    "    \n",
    "    author = str(author)\n",
    "    \n",
    "    if author == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    author = author.split(',')\n",
    "\n",
    "    if len(author) == 1:\n",
    "        name = filter(lambda x: x.isalpha(), author[0])\n",
    "        return reduce(lambda x, y: x + y, name)\n",
    "    \n",
    "    last_name, first_name = author[0], author[1]\n",
    "\n",
    "    first_name = first_name[:first_name.find('-')] if '-' in first_name else first_name\n",
    "    \n",
    "    if first_name.endswith(('.', '.|')):\n",
    "        parts = first_name.split('.')\n",
    "        \n",
    "        if len(parts) > 1:\n",
    "            first_occurence = first_name.find('.')\n",
    "            final_occurence = first_name.find('.', first_occurence + 1)\n",
    "            first_name = first_name[:final_occurence]\n",
    "        else:\n",
    "            first_name = first_name[:first_name.find('.')]\n",
    "    \n",
    "    last_name = last_name.capitalize()\n",
    "    \n",
    "    return f'{first_name} {last_name}'\n",
    "\n",
    "\n",
    "df['Author'] = df['Author'].apply(clean_author_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    \n",
    "    if title == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    if title[0] == '[':\n",
    "        title = title[1: title.find(']')]\n",
    "        \n",
    "    if 'by' in title:\n",
    "        title = title[:title.find('by')]\n",
    "    elif 'By' in title:\n",
    "        title = title[:title.find('By')]\n",
    "        \n",
    "    if '[' in title:\n",
    "        title = title[:title.find('[')]\n",
    "\n",
    "    title = title[:-2]\n",
    "        \n",
    "    title = list(map(str.capitalize, title.split()))\n",
    "    return ' '.join(title)\n",
    "    \n",
    "df['Title'] = df['Title'].apply(clean_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `.str` methods to clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4157862 and 4159587\n",
    "df.loc[4159587]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = df['Place of Publication']\n",
    "df['Place of Publication'] = np.where(pub.str.contains('London'), 'London',\n",
    "    np.where(pub.str.contains('Oxford'), 'Oxford',\n",
    "        np.where(pub.eq('Newcastle upon Tyne'),\n",
    "            'Newcastle-upon-Tyne', df['Place of Publication'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!more Datasets/university_towns.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_towns = []\n",
    "\n",
    "with open('Datasets/university_towns.txt', 'r') as file:\n",
    "    items = file.readlines()\n",
    "    states = list(filter(lambda x: '[edit]' in x, items))\n",
    "    \n",
    "    for index, state in enumerate(states):\n",
    "        start = items.index(state) + 1\n",
    "        if index == 49: #since 50 states\n",
    "            end = len(items)\n",
    "        else:\n",
    "            end = items.index(states[index + 1])\n",
    "            \n",
    "        pairs = map(lambda x: [state, x], items[start:end])\n",
    "        university_towns.extend(pairs)\n",
    "        \n",
    "towns_df = pd.DataFrame(university_towns, columns = ['State', 'RegionName'])\n",
    "towns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(item):\n",
    "    if '(' in item:\n",
    "        return item[:item.find('(') - 1]\n",
    "    \n",
    "    if '[' in item:\n",
    "        return item[:item.find('[')]\n",
    "    \n",
    "\n",
    "towns_df =  towns_df.applymap(clean_up)\n",
    "towns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns and skipping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('Datasets/olympics.csv')\n",
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('Datasets/olympics.csv', skiprows = 1, header = 0)\n",
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names =  {'Unnamed: 0': 'Country',\n",
    "              '? Summer': 'Summer Olympics',\n",
    "              '01 !': 'Gold',\n",
    "              '02 !': 'Silver',\n",
    "              '03 !': 'Bronze',\n",
    "              '? Winter': 'Winter Olympics',\n",
    "              '01 !.1': 'Gold.1',\n",
    "              '02 !.1': 'Silver.1',\n",
    "              '03 !.1': 'Bronze.1',\n",
    "              '? Games': '# Games', \n",
    "              '01 !.2': 'Gold.2',\n",
    "              '02 !.2': 'Silver.2',\n",
    "              '03 !.2': 'Bronze.2'}\n",
    "\n",
    "olympics_df.rename(columns = new_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
